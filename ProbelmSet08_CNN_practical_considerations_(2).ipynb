{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProbelmSet08_CNN_practical_considerations (2).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoKGHVI2gK_E"
      },
      "source": [
        "This notebook is part the of Dr. Christoforos Christoforou's course materials. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials or any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e09u6xTYeaoX"
      },
      "source": [
        "## Problem Set 09: Practical Consideration in CNN\n",
        "\n",
        "For this problem set, you are expected to load an external dataset, and build a convolutional neural network that classifies images of Cat and Dogs. You are expected to implement the network based on the practical considerations outlined in the corresponding lecture. REview the video lecture of this course to complete the assignment. You wull need the following libraries to complete this probelem set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfzcLMsPkGb0"
      },
      "source": [
        "# Load general numpy and pandas \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# Load tensorflow libraries \n",
        "import tensorflow \n",
        "from tensorflow.keras import backend\n",
        "\n",
        "\n",
        "# Dataset Libraries \n",
        "from tensorflow.keras.datasets import fashion_mnist "
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7BlHOE_gYmn"
      },
      "source": [
        "import os\n",
        "import tensorflow.keras \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Conv2D, MaxPool2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "## Add any missing libraries "
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfqRWCuAgicK"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Create a convolutional neural network to classify images in the above dataset to either Cat or Dogs. Your solution should comply with the following requirements:\n",
        "\n",
        "* Build computational blocks that include a sqeunce of `Covolution Layer`-> `BatchNormailization` -> `Activation` -> `Max Pooling` -> `Dropout Layer`.\n",
        "* Build computational blocks that include a sequence of `Dense Layer`-> `BatchNormailization Layer` -> `Activation function` -> `Max Pooling`.\n",
        "* Build a model that utilizes the above computational blocks. You can use additional layers if you like.\n",
        "* Create a manual split of the dataset set into a `Training Set` and `Validation Set`. You are expected to store the training and validation set into separate filders so they can be loaded using the `ImageDataGenerator` class.\n",
        "* Prepare `ImageDataGenerator` objects to load batches of training and validation images from the corresponding folders. Add an image augmentation layer and make sure you use the `flow_from_directory` method.\n",
        "* Train the model using `EarlyStopping` and `ModelCheckpoint` callback functions.\n",
        "* Report validation performance on each epoch.\n",
        "* Fine-tune your model to achieve classification performance above 80%.\n",
        "* Save the best model.\n",
        "* Load the best model and display the model structure (i.e. using the `model.summary()` method. \n",
        "\n",
        "\n",
        "Use as many cells as you need to complete the problem set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80gXdanCgZ2v"
      },
      "source": [
        "Copyright Statement: Copyright © 2020 Christoforou. The materials provided by the instructor of this course, including this notebook, are for the use of the students enrolled in the course. Materials are presented in an educational context for personal use and study and should not be shared, distributed, disseminated or sold in print — or digitally — outside the course without permission. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials as well as any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnXK7R_iz4ay"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBRMeB71zzL1"
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  \n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  \n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  "
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfxdHXNsz2Dl"
      },
      "source": [
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5mohKNxFIC"
      },
      "source": [
        "BATCH_SIZE = 30\n",
        "img_shape  = 150  "
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMfe4BsOxhFN"
      },
      "source": [
        "train_image_generator      = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWbA3h2Pxjp9",
        "outputId": "d96287b7-9d8c-4388-b1f1-afc46a230a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(img_shape,img_shape), \n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGEfNrXdxoph",
        "outputId": "8e304cc5-227c-45d5-cf94-39db42b8bb45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(img_shape,img_shape), \n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4-UDNu1xuW4"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen) "
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUalsw_4x3st"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(2))\n"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYimEwziyPJz",
        "outputId": "08068577-c8be-4bc0-d417-86f0273287ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 18, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 512)               5308928   \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 5,310,850\n",
            "Trainable params: 5,310,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNono5ffyMs8",
        "outputId": "3f363c6a-9517-4a37-c346-7b1eb7ecfd8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=15,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))),\n",
        "    callbacks=[callback]\n",
        ")\n"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "67/67 [==============================] - 38s 574ms/step - loss: 0.4561 - accuracy: 0.7980 - val_loss: 0.6147 - val_accuracy: 0.6610\n",
            "Epoch 2/15\n",
            "67/67 [==============================] - 38s 572ms/step - loss: 0.3980 - accuracy: 0.8200 - val_loss: 0.5898 - val_accuracy: 0.6870\n",
            "Epoch 3/15\n",
            "67/67 [==============================] - 38s 569ms/step - loss: 0.3644 - accuracy: 0.8435 - val_loss: 0.5540 - val_accuracy: 0.7190\n",
            "Epoch 4/15\n",
            "67/67 [==============================] - 40s 591ms/step - loss: 0.2940 - accuracy: 0.8795 - val_loss: 0.5671 - val_accuracy: 0.7080\n",
            "Epoch 5/15\n",
            "67/67 [==============================] - 39s 575ms/step - loss: 0.2635 - accuracy: 0.8945 - val_loss: 0.6050 - val_accuracy: 0.6850\n",
            "Epoch 6/15\n",
            "67/67 [==============================] - 39s 576ms/step - loss: 0.2373 - accuracy: 0.9090 - val_loss: 0.6272 - val_accuracy: 0.6990\n",
            "Epoch 7/15\n",
            "67/67 [==============================] - 38s 574ms/step - loss: 0.2132 - accuracy: 0.9190 - val_loss: 0.6050 - val_accuracy: 0.7110\n",
            "Epoch 8/15\n",
            "67/67 [==============================] - 39s 577ms/step - loss: 0.1747 - accuracy: 0.9345 - val_loss: 0.6268 - val_accuracy: 0.7190\n",
            "Epoch 9/15\n",
            "67/67 [==============================] - 39s 580ms/step - loss: 0.1357 - accuracy: 0.9475 - val_loss: 0.6522 - val_accuracy: 0.7120\n",
            "Epoch 10/15\n",
            "67/67 [==============================] - 38s 567ms/step - loss: 0.1197 - accuracy: 0.9590 - val_loss: 0.6702 - val_accuracy: 0.7100\n",
            "Epoch 11/15\n",
            "67/67 [==============================] - 38s 573ms/step - loss: 0.1393 - accuracy: 0.9465 - val_loss: 0.6775 - val_accuracy: 0.6920\n",
            "Epoch 12/15\n",
            "67/67 [==============================] - 39s 586ms/step - loss: 0.1006 - accuracy: 0.9640 - val_loss: 0.7096 - val_accuracy: 0.6990\n",
            "Epoch 13/15\n",
            "67/67 [==============================] - 38s 566ms/step - loss: 0.0810 - accuracy: 0.9760 - val_loss: 0.7482 - val_accuracy: 0.6980\n",
            "Epoch 14/15\n",
            "67/67 [==============================] - 38s 571ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.7554 - val_accuracy: 0.7030\n",
            "Epoch 15/15\n",
            "67/67 [==============================] - 38s 571ms/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 0.7820 - val_accuracy: 0.6990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3I-m8l4lGB",
        "outputId": "a70cc170-4572-4a6f-8454-e0b37d4e7648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "print(\"Accuracy\" , acc, '\\n')\n",
        "print(\"Value Accuracy\", val_acc, '\\n')\n",
        "print(\"Loss\", loss, '\\n')\n",
        "print(\"Value Loss\", val_loss, '\\n')\n",
        "print(\"Epoch Range\", epochs_range, 'n')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy [0.7979999780654907, 0.8199999928474426, 0.843500018119812, 0.8794999718666077, 0.8945000171661377, 0.9089999794960022, 0.9190000295639038, 0.934499979019165, 0.9474999904632568, 0.9589999914169312, 0.9465000033378601, 0.9639999866485596, 0.9760000109672546, 0.9695000052452087, 0.9775000214576721] \n",
            "\n",
            "Value Accuracy [0.6610000133514404, 0.6869999766349792, 0.718999981880188, 0.7080000042915344, 0.6850000023841858, 0.6990000009536743, 0.7110000252723694, 0.718999981880188, 0.7120000123977661, 0.7099999785423279, 0.6919999718666077, 0.6990000009536743, 0.6980000138282776, 0.703000009059906, 0.6990000009536743] \n",
            "\n",
            "Loss [0.45606499910354614, 0.39799603819847107, 0.3643592298030853, 0.2939690053462982, 0.26345202326774597, 0.23725271224975586, 0.21324415504932404, 0.17471668124198914, 0.1356980949640274, 0.11967170983552933, 0.13928097486495972, 0.10056712478399277, 0.08100325614213943, 0.07885374873876572, 0.06874213367700577] \n",
            "\n",
            "Value Loss [0.6146973371505737, 0.5897642970085144, 0.5540316700935364, 0.5670890212059021, 0.6049955487251282, 0.6272134184837341, 0.604977548122406, 0.6267737746238708, 0.652225136756897, 0.6702296137809753, 0.6774725914001465, 0.7095987200737, 0.7482197880744934, 0.7554453611373901, 0.7820470929145813] \n",
            "\n",
            "Epoch Range range(0, 10) n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}